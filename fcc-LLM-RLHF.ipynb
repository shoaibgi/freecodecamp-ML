{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13612980,"sourceType":"datasetVersion","datasetId":8651087},{"sourceId":13613320,"sourceType":"datasetVersion","datasetId":8651365}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.version.cuda)\nprint(torch.cuda.get_device_name(0))","metadata":{"_uuid":"8d26740c-febb-4e02-91a6-5d36126287fb","_cell_guid":"741e6ce6-28f5-4d51-b504-bbdc53c3a8e9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-04T16:02:04.462826Z","iopub.execute_input":"2025-11-04T16:02:04.463093Z","iopub.status.idle":"2025-11-04T16:02:04.468223Z","shell.execute_reply.started":"2025-11-04T16:02:04.463074Z","shell.execute_reply":"2025-11-04T16:02:04.467441Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"True\n12.4\nTesla T4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -r /kaggle/input/llm-data/requirements.txt ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:14:32.306768Z","iopub.execute_input":"2025-11-04T16:14:32.307041Z","iopub.status.idle":"2025-11-04T16:18:35.947967Z","shell.execute_reply.started":"2025-11-04T16:14:32.307020Z","shell.execute_reply":"2025-11-04T16:18:35.947258Z"}},"outputs":[{"name":"stdout","text":"Collecting absl-py==2.3.1 (from -r /kaggle/input/llm-data/requirements.txt (line 1))\n  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 2)) (2.6.1)\nRequirement already satisfied: aiohttp==3.12.15 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 3)) (3.12.15)\nRequirement already satisfied: aiosignal==1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 4)) (1.4.0)\nRequirement already satisfied: attrs==25.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 5)) (25.3.0)\nRequirement already satisfied: certifi==2025.8.3 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 6)) (2025.8.3)\nRequirement already satisfied: charset-normalizer==3.4.3 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 7)) (3.4.3)\nCollecting contourpy==1.3.3 (from -r /kaggle/input/llm-data/requirements.txt (line 8))\n  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 9)) (0.12.1)\nCollecting datasets==4.0.0 (from -r /kaggle/input/llm-data/requirements.txt (line 10))\n  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\nCollecting dill==0.3.8 (from -r /kaggle/input/llm-data/requirements.txt (line 11))\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: filelock==3.19.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 12)) (3.19.1)\nCollecting fonttools==4.59.1 (from -r /kaggle/input/llm-data/requirements.txt (line 13))\n  Downloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (108 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: frozenlist==1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 14)) (1.7.0)\nCollecting fsspec==2025.3.0 (from -r /kaggle/input/llm-data/requirements.txt (line 15))\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting grpcio==1.74.0 (from -r /kaggle/input/llm-data/requirements.txt (line 16))\n  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting hf-xet==1.1.7 (from -r /kaggle/input/llm-data/requirements.txt (line 17))\n  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\nCollecting huggingface-hub==0.34.4 (from -r /kaggle/input/llm-data/requirements.txt (line 18))\n  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 19)) (3.10)\nRequirement already satisfied: iniconfig==2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 20)) (2.1.0)\nRequirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 21)) (3.1.6)\nCollecting kiwisolver==1.4.9 (from -r /kaggle/input/llm-data/requirements.txt (line 22))\n  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: Markdown==3.8.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 23)) (3.8.2)\nRequirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 24)) (3.0.2)\nCollecting matplotlib==3.10.5 (from -r /kaggle/input/llm-data/requirements.txt (line 25))\n  Downloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 26)) (1.3.0)\nRequirement already satisfied: multidict==6.6.4 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 27)) (6.6.4)\nRequirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 28)) (0.70.16)\nRequirement already satisfied: networkx==3.5 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 29)) (3.5)\nCollecting numpy==2.3.2 (from -r /kaggle/input/llm-data/requirements.txt (line 30))\n  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging==25.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 31)) (25.0)\nCollecting pandas==2.3.2 (from -r /kaggle/input/llm-data/requirements.txt (line 32))\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow==11.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 33)) (11.3.0)\nRequirement already satisfied: pluggy==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 34)) (1.6.0)\nRequirement already satisfied: propcache==0.3.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 35)) (0.3.2)\nCollecting protobuf==6.32.0 (from -r /kaggle/input/llm-data/requirements.txt (line 36))\n  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nCollecting pyarrow==21.0.0 (from -r /kaggle/input/llm-data/requirements.txt (line 37))\n  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: Pygments==2.19.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 38)) (2.19.2)\nCollecting pyparsing==3.2.3 (from -r /kaggle/input/llm-data/requirements.txt (line 39))\n  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: pytest==8.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 40)) (8.4.1)\nRequirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 41)) (2.9.0.post0)\nRequirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 42)) (2025.2)\nCollecting PyYAML==6.0.2 (from -r /kaggle/input/llm-data/requirements.txt (line 43))\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nCollecting requests==2.32.4 (from -r /kaggle/input/llm-data/requirements.txt (line 44))\n  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 45)) (1.17.0)\nCollecting sympy==1.14.0 (from -r /kaggle/input/llm-data/requirements.txt (line 46))\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting tensorboard==2.20.0 (from -r /kaggle/input/llm-data/requirements.txt (line 47))\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 48)) (0.7.2)\nCollecting tokenizers==0.21.4 (from -r /kaggle/input/llm-data/requirements.txt (line 49))\n  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting torch==2.8.0 (from -r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nRequirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 51)) (4.67.1)\nCollecting typing_extensions==4.14.1 (from -r /kaggle/input/llm-data/requirements.txt (line 52))\n  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 53)) (2025.2)\nRequirement already satisfied: urllib3==2.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 54)) (2.5.0)\nRequirement already satisfied: Werkzeug==3.1.3 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 55)) (3.1.3)\nRequirement already satisfied: xxhash==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 56)) (3.5.0)\nRequirement already satisfied: yarl==1.20.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/llm-data/requirements.txt (line 57)) (1.20.1)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.20.0->-r /kaggle/input/llm-data/requirements.txt (line 47)) (75.2.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.4.0 (from torch==2.8.0->-r /kaggle/input/llm-data/requirements.txt (line 50))\n  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, typing_extensions, triton, sympy, requests, PyYAML, pyparsing, pyarrow, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, kiwisolver, hf-xet, grpcio, fsspec, fonttools, dill, absl-py, tensorboard, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, contourpy, tokenizers, nvidia-cusolver-cu12, matplotlib, torch, datasets\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: typing_extensions\n    Found existing installation: typing_extensions 4.15.0\n    Uninstalling typing_extensions-4.15.0:\n      Successfully uninstalled typing_extensions-4.15.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.5\n    Uninstalling requests-2.32.5:\n      Successfully uninstalled requests-2.32.5\n  Attempting uninstall: PyYAML\n    Found existing installation: PyYAML 6.0.3\n    Uninstalling PyYAML-6.0.3:\n      Successfully uninstalled PyYAML-6.0.3\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.0.9\n    Uninstalling pyparsing-3.0.9:\n      Successfully uninstalled pyparsing-3.0.9\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: kiwisolver\n    Found existing installation: kiwisolver 1.4.8\n    Uninstalling kiwisolver-1.4.8:\n      Successfully uninstalled kiwisolver-1.4.8\n  Attempting uninstall: hf-xet\n    Found existing installation: hf-xet 1.1.10\n    Uninstalling hf-xet-1.1.10:\n      Successfully uninstalled hf-xet-1.1.10\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.75.1\n    Uninstalling grpcio-1.75.1:\n      Successfully uninstalled grpcio-1.75.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.9.0\n    Uninstalling fsspec-2025.9.0:\n      Successfully uninstalled fsspec-2025.9.0\n  Attempting uninstall: fonttools\n    Found existing installation: fonttools 4.59.0\n    Uninstalling fonttools-4.59.0:\n      Successfully uninstalled fonttools-4.59.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.4.0\n    Uninstalling dill-0.4.0:\n      Successfully uninstalled dill-0.4.0\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: contourpy\n    Found existing installation: contourpy 1.3.2\n    Uninstalling contourpy-1.3.2:\n      Successfully uninstalled contourpy-1.3.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Uninstalling matplotlib-3.7.2:\n      Successfully uninstalled matplotlib-3.7.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.1.1\n    Uninstalling datasets-4.1.1:\n      Successfully uninstalled datasets-4.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.2 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.32.0 which is incompatible.\nydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.5 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.2 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.32.0 which is incompatible.\ngoogle-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.0 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\ndataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PyYAML-6.0.2 absl-py-2.3.1 contourpy-1.3.3 datasets-4.0.0 dill-0.3.8 fonttools-4.59.1 fsspec-2025.3.0 grpcio-1.74.0 hf-xet-1.1.7 huggingface-hub-0.34.4 kiwisolver-1.4.9 matplotlib-3.10.5 numpy-2.3.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pandas-2.3.2 protobuf-6.32.0 pyarrow-21.0.0 pyparsing-3.2.3 requests-2.32.4 sympy-1.14.0 tensorboard-2.20.0 tokenizers-0.21.4 torch-2.8.0 triton-3.4.0 typing_extensions-4.14.1\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\n\ndef causal_mask(T: int, device=None):\n    \"\"\"Returns a bool mask where True means *masked* (disallowed).\n    Shape: (1, 1, T, T) suitable for broadcasting with (B, heads, T, T).\n    \"\"\"\n    m = torch.triu(torch.ones((T, T), dtype=torch.bool, device=device), diagonal=1)\n    return m.view(1, 1, T, T)","metadata":{"_uuid":"0d87a454-79c2-4de1-b386-91de9d1a36f4","_cell_guid":"01b208a2-a1c8-4de3-a6fa-83f3c02809c1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-04T16:02:07.216261Z","iopub.execute_input":"2025-11-04T16:02:07.216922Z","iopub.status.idle":"2025-11-04T16:02:07.220860Z","shell.execute_reply.started":"2025-11-04T16:02:07.216895Z","shell.execute_reply":"2025-11-04T16:02:07.220087Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\n\nnp.set_printoptions(precision=4, suppress=True)\n\n# Toy inputs (batch=1, seq=3, d_model=4)\nX = np.array([[[0.1, 0.2, 0.3, 0.4],\n               [0.5, 0.4, 0.3, 0.2],\n               [0.0, 0.1, 0.0, 0.1]]], dtype=np.float32)\n\n# Weight matrices (learned in real models). We fix numbers for determinism.\nWq = np.array([[ 0.2, -0.1],\n               [ 0.0,  0.1],\n               [ 0.1,  0.2],\n               [-0.1,  0.0]], dtype=np.float32)\nWk = np.array([[ 0.1,  0.1],\n               [ 0.0, -0.1],\n               [ 0.2,  0.0],\n               [ 0.0,  0.2]], dtype=np.float32)\nWv = np.array([[ 0.1,  0.0],\n               [-0.1,  0.1],\n               [ 0.2, -0.1],\n               [ 0.0,  0.2]], dtype=np.float32)\n\n# Project to Q, K, V\nQ = X @ Wq  # (1,3,2)\nK = X @ Wk  # (1,3,2)\nV = X @ Wv  # (1,3,2)\n\nprint(\"Q shape:\", Q.shape, \"\\nQ=\\n\", Q[0])\nprint(\"K shape:\", K.shape, \"\\nK=\\n\", K[0])\nprint(\"V shape:\", V.shape, \"\\nV=\\n\", V[0])\n\n# Scaled dot-products\nscale = 1.0 / np.sqrt(Q.shape[-1])\nattn_scores = (Q @ K.transpose(0,2,1)) * scale  # (1,3,3)\n\n# Causal mask (upper triangle set to -inf so softmax->0)\nmask = np.triu(np.ones((1,3,3), dtype=bool), k=1)\nattn_scores = np.where(mask, -1e9, attn_scores)\n\n# Softmax over last dim\nweights = np.exp(attn_scores - attn_scores.max(axis=-1, keepdims=True))\nweights = weights / weights.sum(axis=-1, keepdims=True)\nprint(\"Weights shape:\", weights.shape, \"\\nAttention Weights (causal)=\\n\", weights[0])\n\n# Weighted sum of V\nout = weights @ V  # (1,3,2)\nprint(\"Output shape:\", out.shape, \"\\nOutput=\\n\", out[0])","metadata":{"_uuid":"b636a4be-5e0a-4e52-ac0c-7b7962ce2919","_cell_guid":"0ff4c6a3-0991-41b9-9176-0129221b05d8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-04T16:02:13.428665Z","iopub.execute_input":"2025-11-04T16:02:13.428928Z","iopub.status.idle":"2025-11-04T16:02:13.438930Z","shell.execute_reply.started":"2025-11-04T16:02:13.428910Z","shell.execute_reply":"2025-11-04T16:02:13.438179Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Q shape: (1, 3, 2) \nQ=\n [[ 0.01  0.07]\n [ 0.11  0.05]\n [-0.01  0.01]]\nK shape: (1, 3, 2) \nK=\n [[0.07 0.07]\n [0.11 0.05]\n [0.   0.01]]\nV shape: (1, 3, 2) \nV=\n [[ 0.05  0.07]\n [ 0.07  0.05]\n [-0.01  0.03]]\nWeights shape: (1, 3, 3) \nAttention Weights (causal)=\n [[1.     0.     0.    ]\n [0.4994 0.5006 0.    ]\n [0.3334 0.3332 0.3334]]\nOutput shape: (1, 3, 2) \nOutput=\n [[0.05   0.07  ]\n [0.06   0.06  ]\n [0.0367 0.05  ]]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch.nn as nn\n##from multi_head import MultiHeadSelfAttention\n##from ffn import FeedForward\n\nclass TransformerBlock(nn.Module):\n    \"\"\"1.6 Transformer block = LN → MHA → residual → LN → FFN → residual.\"\"\"\n    def __init__(self, d_model: int, n_head: int, dropout: float = 0.0):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(d_model)\n        self.attn = MultiHeadSelfAttention(d_model, n_head, dropout)\n        self.ln2 = nn.LayerNorm(d_model)\n        self.ffn = FeedForward(d_model, mult=4, dropout=dropout)\n\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))[0]\n        x = x + self.ffn(self.ln2(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:19:42.988958Z","iopub.execute_input":"2025-11-04T16:19:42.989810Z","iopub.status.idle":"2025-11-04T16:19:42.995774Z","shell.execute_reply.started":"2025-11-04T16:19:42.989780Z","shell.execute_reply":"2025-11-04T16:19:42.994976Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import os\nimport math\nimport torch\n##from multi_head import MultiHeadSelfAttention\n\nOUT_TXT = os.path.join('/kaggle/working', 'mha_shapes.txt')\n\n\ndef log(s):\n    print(s)\n    with open(OUT_TXT, 'a') as f:\n        f.write(s + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    # Reset file\n    os.makedirs(os.path.dirname(OUT_TXT), exist_ok=True)\n    open(OUT_TXT, 'w').close()\n\n    B, T, d_model, n_head = 1, 5, 12, 3\n    d_head = d_model // n_head\n    x = torch.randn(B, T, d_model)\n    attn = MultiHeadSelfAttention(d_model, n_head, trace_shapes=True)\n\n    log(f\"Input x:           {tuple(x.shape)} = (B,T,d_model)\")\n    qkv = attn.qkv(x)  # (B,T,3*d_model)\n    log(f\"Linear qkv(x):     {tuple(qkv.shape)} = (B,T,3*d_model)\")\n\n    qkv = qkv.view(B, T, 3, n_head, d_head)\n    log(f\"view to 5D:        {tuple(qkv.shape)} = (B,T,3,heads,d_head)\")\n\n    q, k, v = qkv.unbind(dim=2)\n    log(f\"q,k,v split:       q={tuple(q.shape)} k={tuple(k.shape)} v={tuple(v.shape)}\")\n\n    q = q.transpose(1, 2)\n    k = k.transpose(1, 2)\n    v = v.transpose(1, 2)\n    log(f\"transpose heads:   q={tuple(q.shape)} k={tuple(k.shape)} v={tuple(v.shape)} = (B,heads,T,d_head)\")\n\n    scale = 1.0 / math.sqrt(d_head)\n    scores = torch.matmul(q, k.transpose(-2, -1)) * scale\n    log(f\"scores q@k^T:      {tuple(scores.shape)} = (B,heads,T,T)\")\n\n    weights = torch.softmax(scores, dim=-1)\n    log(f\"softmax(weights):  {tuple(weights.shape)} = (B,heads,T,T)\")\n\n    ctx = torch.matmul(weights, v)\n    log(f\"context @v:        {tuple(ctx.shape)} = (B,heads,T,d_head)\")\n\n    out = ctx.transpose(1, 2).contiguous().view(B, T, d_model)\n    log(f\"merge heads:       {tuple(out.shape)} = (B,T,d_model)\")\n\n    out = attn.proj(out)\n    log(f\"final proj:        {tuple(out.shape)} = (B,T,d_model)\")\n\n    log(\"\\nLegend:\")\n    log(\"  B=batch, T=sequence length, d_model=embedding size, heads=n_head, d_head=d_model/heads\")\n    log(\"  qkv(x) is a single Linear producing [Q|K|V]; we reshape then split into q,k,v\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T16:31:04.381029Z","iopub.execute_input":"2025-11-04T16:31:04.381726Z","iopub.status.idle":"2025-11-04T16:31:04.402991Z","shell.execute_reply.started":"2025-11-04T16:31:04.381700Z","shell.execute_reply":"2025-11-04T16:31:04.402307Z"}},"outputs":[{"name":"stdout","text":"Input x:           (1, 5, 12) = (B,T,d_model)\nLinear qkv(x):     (1, 5, 36) = (B,T,3*d_model)\nview to 5D:        (1, 5, 3, 3, 4) = (B,T,3,heads,d_head)\nq,k,v split:       q=(1, 5, 3, 4) k=(1, 5, 3, 4) v=(1, 5, 3, 4)\ntranspose heads:   q=(1, 3, 5, 4) k=(1, 3, 5, 4) v=(1, 3, 5, 4) = (B,heads,T,d_head)\nscores q@k^T:      (1, 3, 5, 5) = (B,heads,T,T)\nsoftmax(weights):  (1, 3, 5, 5) = (B,heads,T,T)\ncontext @v:        (1, 3, 5, 4) = (B,heads,T,d_head)\nmerge heads:       (1, 5, 12) = (B,T,d_model)\nfinal proj:        (1, 5, 12) = (B,T,d_model)\n\nLegend:\n  B=batch, T=sequence length, d_model=embedding size, heads=n_head, d_head=d_model/heads\n  qkv(x) is a single Linear producing [Q|K|V]; we reshape then split into q,k,v\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nOUT_DIR = os.path.join('/kaggle/working', 'mha.jpeg')\n\n\ndef _ensure_out():\n    os.makedirs(OUT_DIR, exist_ok=True)\n\n\ndef save_matrix_heatmap(mat: np.ndarray, title: str, filename: str, xlabel: str = '', ylabel: str = ''):\n    \"\"\"Generic matrix heatmap saver.\n    Do not set any specific colors/styles; keep defaults for clarity.\n    \"\"\"\n    _ensure_out()\n    plt.figure()\n    plt.imshow(mat, aspect='auto')\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.colorbar()\n    path = os.path.join(OUT_DIR, filename)\n    plt.savefig(path, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved: {path}\")\n\n\ndef save_attention_heads_grid(weights: np.ndarray, filename: str, title_prefix: str = \"Head\"):\n    \"\"\"Plot all heads in a single grid figure (B=1 assumed).\n    weights: (1, H, T, T)\n    \"\"\"\n    _ensure_out()\n    _, H, T, _ = weights.shape\n    cols = min(4, H)\n    rows = (H + cols - 1) // cols\n    plt.figure(figsize=(3*cols, 3*rows))\n    for h in range(H):\n        ax = plt.subplot(rows, cols, h+1)\n        ax.imshow(weights[0, h], aspect='auto')\n        ax.set_title(f\"{title_prefix} {h}\")\n        ax.set_xlabel('Key pos')\n        ax.set_ylabel('Query pos')\n    plt.tight_layout()\n    path = os.path.join(OUT_DIR, filename)\n    plt.savefig(path, bbox_inches='tight')\n    print(f\"Saved: {path}\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:07:43.424855Z","iopub.execute_input":"2025-11-04T17:07:43.425577Z","iopub.status.idle":"2025-11-04T17:07:43.432823Z","shell.execute_reply.started":"2025-11-04T17:07:43.425554Z","shell.execute_reply":"2025-11-04T17:07:43.432027Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import torch\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n##from multi_head import MultiHeadSelfAttention\n##from vis_utils import save_attention_heads_grid\n\nB, T, d_model, n_head = 1, 5, 12, 3\nx = torch.randn(B, T, d_model)\nattn = MultiHeadSelfAttention(d_model, n_head, trace_shapes=False)\n\nout, w = attn(x)  # w: (B, H, T, T)\n\nsave_attention_heads_grid(w.detach().cpu().numpy(), filename=\"multi_head_attn_grid.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:07:58.902339Z","iopub.execute_input":"2025-11-04T17:07:58.903078Z","iopub.status.idle":"2025-11-04T17:07:59.600752Z","shell.execute_reply.started":"2025-11-04T17:07:58.903052Z","shell.execute_reply":"2025-11-04T17:07:59.600007Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/mha.jpeg/multi_head_attn_grid.png\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 900x300 with 3 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import torch.nn as nn\n\nclass FeedForward(nn.Module):\n    \"\"\"1.5 FFN with expansion factor `mult`.\n\n    Dimensions:\n      input:     (B, T, d_model)\n      inner:     (B, T, mult*d_model)\n      output:    (B, T, d_model)\n\n    `mult*d_model` means the hidden width is `mult` times larger than `d_model`.\n    Typical values: mult=4 for GELU FFN in GPT-style blocks.\n    \"\"\"\n    def __init__(self, d_model: int, mult: int = 4, dropout: float = 0.0):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(d_model, mult * d_model),\n            nn.GELU(),\n            nn.Linear(mult * d_model, d_model),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:05:51.257342Z","iopub.execute_input":"2025-11-04T17:05:51.257979Z","iopub.status.idle":"2025-11-04T17:05:51.263250Z","shell.execute_reply.started":"2025-11-04T17:05:51.257952Z","shell.execute_reply":"2025-11-04T17:05:51.262576Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n##from attn_mask import causal_mask\n\nclass MultiHeadSelfAttention(nn.Module):\n    \"\"\"1.4 Multi-head attention with explicit shape tracing.\n\n    Dimensions (before masking):\n      x:      (B, T, d_model)\n      qkv:    (B, T, 3*d_model)\n      view→   (B, T, 3, n_head, d_head)   where d_head = d_model // n_head\n      split→  q,k,v each (B, T, n_head, d_head)\n      swap→   (B, n_head, T, d_head)\n      scores: (B, n_head, T, T) = q @ k^T / sqrt(d_head)\n      weights:(B, n_head, T, T) = softmax(scores)\n      ctx:    (B, n_head, T, d_head) = weights @ v\n      merge:  (B, T, n_head*d_head) = (B, T, d_model)\n    \"\"\"\n    def __init__(self, d_model: int, n_head: int, dropout: float = 0.0, trace_shapes: bool = True):\n        super().__init__()\n        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n        self.n_head = n_head\n        self.d_head = d_model // n_head\n        self.qkv = nn.Linear(d_model, 3 * d_model, bias=False)\n        self.proj = nn.Linear(d_model, d_model, bias=False)\n        self.dropout = nn.Dropout(dropout)\n        self.trace_shapes = trace_shapes\n\n    def forward(self, x: torch.Tensor):  # (B,T,d_model)\n        B, T, C = x.shape\n        qkv = self.qkv(x)                          # (B,T,3*C)\n        qkv = qkv.view(B, T, 3, self.n_head, self.d_head)  # (B,T,3,heads,dim)\n        if self.trace_shapes:\n            print(\"qkv view:\", qkv.shape)\n        q, k, v = qkv.unbind(dim=2)               # each: (B,T,heads,dim)\n        q = q.transpose(1, 2)                      # (B,heads,T,dim)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        if self.trace_shapes:\n            print(\"q:\", q.shape, \"k:\", k.shape, \"v:\", v.shape)\n\n        scale = 1.0 / math.sqrt(self.d_head)\n        attn = torch.matmul(q, k.transpose(-2, -1)) * scale  # (B,heads,T,T)\n        mask = causal_mask(T, device=x.device)\n        attn = attn.masked_fill(mask, float('-inf'))\n        w = F.softmax(attn, dim=-1)\n        w = self.dropout(w)\n        ctx = torch.matmul(w, v)                  # (B,heads,T,dim)\n        if self.trace_shapes:\n            print(\"weights:\", w.shape, \"ctx:\", ctx.shape)\n        out = ctx.transpose(1, 2).contiguous().view(B, T, C)  # (B,T,d_model)\n        out = self.proj(out)\n        if self.trace_shapes:\n            print(\"out:\", out.shape)\n        return out, w\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:05:02.385117Z","iopub.execute_input":"2025-11-04T17:05:02.385703Z","iopub.status.idle":"2025-11-04T17:05:02.394273Z","shell.execute_reply.started":"2025-11-04T17:05:02.385679Z","shell.execute_reply":"2025-11-04T17:05:02.393537Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import subprocess, sys, pathlib, argparse, shlex\n\nROOT = pathlib.Path(__file__).resolve().parent\nOUT = ROOT / \"out\"\n\n\ndef run(cmd: str):\n    print(f\"\\n>>> {cmd}\")\n    res = subprocess.run(shlex.split(cmd), cwd=ROOT)\n    if res.returncode != 0:\n        sys.exit(res.returncode)\n\n\ndef main():\n    p = argparse.ArgumentParser()\n    p.add_argument(\"--visualize\", action=\"store_true\", help=\"run visualization scripts and save PNGs to ./out\")\n    args = p.parse_args()\n\n    OUT.mkdir(exist_ok=True)\n\n    # 1.2 sanity check: NumPy tiny example\n    run(\"python attn_numpy_demo.py\")\n\n    # 1.3/1.4 unit tests\n    run(\"python -m pytest -q tests/test_attn_math.py\")\n    run(\"python -m pytest -q tests/test_causal_mask.py\")\n\n    # Matrix math walkthrough for MHA\n    run(\"python demo_mha_shapes.py\")\n\n    if args.visualize:\n        run(\"python demo_visualize_multi_head.py\")\n        print(f\"\\nVisualization images saved to: {OUT}\")\n\n    print(\"\\nAll Part 1 demos/tests completed. ✅\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\n\nclass LearnedPositionalEncoding(nn.Module):\n    def __init__(self, max_len: int, d_model: int):\n        super().__init__()\n        self.emb = nn.Embedding(max_len, d_model)\n\n    def forward(self, x: torch.Tensor):\n        # x: (B, T, d_model) — we only need its T and device\n        B, T, _ = x.shape\n        pos = torch.arange(T, device=x.device)\n        pos_emb = self.emb(pos)  # (T, d_model)\n        return x + pos_emb.unsqueeze(0)  # broadcast over batch\n\nclass SinusoidalPositionalEncoding(nn.Module):\n    def __init__(self, max_len: int, d_model: int):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)  # (max_len, d_model)\n\n    def forward(self, x: torch.Tensor):\n        B, T, _ = x.shape\n        return x + self.pe[:T].unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:06:16.001193Z","iopub.execute_input":"2025-11-04T17:06:16.001519Z","iopub.status.idle":"2025-11-04T17:06:16.008637Z","shell.execute_reply.started":"2025-11-04T17:06:16.001498Z","shell.execute_reply":"2025-11-04T17:06:16.007863Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"##from __future__ import annotations\n##from pathlib import Path\nimport torch\n\nclass ByteDataset:\n    \"\"\"Holds raw bytes of a text file and yields (x,y) blocks for LM.\n    - block_size: sequence length (context window)\n    - split: fraction for training (rest is val)\n    \"\"\"\n    def __init__(self, path: str, block_size: int = 256, split: float = 0.9):\n        data = Path(path).read_bytes()\n        data = torch.tensor(list(data), dtype=torch.long)\n        n = int(len(data) * split)\n        self.train = data[:n]\n        self.val = data[n:]\n        self.block_size = block_size\n\n    def get_batch(self, which: str, batch_size: int, device: torch.device):\n        buf = self.train if which == 'train' else self.val\n        assert len(buf) > self.block_size + 1, 'file too small for given block_size'\n        ix = torch.randint(0, len(buf) - self.block_size - 1, (batch_size,))\n        x = torch.stack([buf[i:i+self.block_size] for i in ix])\n        y = torch.stack([buf[i+1:i+1+self.block_size] for i in ix])\n        return x.to(device), y.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:14:35.829188Z","iopub.execute_input":"2025-11-04T17:14:35.830152Z","iopub.status.idle":"2025-11-04T17:14:35.836772Z","shell.execute_reply.started":"2025-11-04T17:14:35.830123Z","shell.execute_reply":"2025-11-04T17:14:35.835946Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"##from __future__ import annotations\nimport argparse, torch\n##from dataset import ByteDataset\n##from model_gpt import GPT\n\n\ndef main():\n    p = argparse.ArgumentParser()\n    p.add_argument('--data', type=str, required=True)\n    p.add_argument('--ckpt', type=str, required=True)\n    p.add_argument('--block_size', type=int, default=256)\n    p.add_argument('--batch_size', type=int, default=32)\n    p.add_argument('--iters', type=int, default=100)\n    p.add_argument('--cpu', action='store_true')\n    args = p.parse_args()\n\n    device = torch.device('cuda' if torch.cuda.is_available() and not args.cpu else 'cpu')\n\n    ds = ByteDataset(args.data, block_size=args.block_size)\n    ckpt = torch.load(args.ckpt, map_location=device)\n    cfg = ckpt.get('config', {\n        'vocab_size': 256,\n        'block_size': args.block_size,\n        'n_layer': 4,\n        'n_head': 4,\n        'n_embd': 256,\n        'dropout': 0.0,\n    })\n    model = GPT(**cfg).to(device)\n    model.load_state_dict(ckpt['model'])\n\n    model.eval()\n    losses = []\n    with torch.no_grad():\n        for _ in range(args.iters):\n            xb, yb = ds.get_batch('val', args.batch_size, device)\n            _, loss = model(xb, yb)\n            losses.append(loss.item())\n    print(f\"val loss: {sum(losses)/len(losses):.4f}\")\n\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:15:23.242373Z","iopub.execute_input":"2025-11-04T17:15:23.242685Z","iopub.status.idle":"2025-11-04T17:15:23.254385Z","shell.execute_reply.started":"2025-11-04T17:15:23.242648Z","shell.execute_reply":"2025-11-04T17:15:23.253283Z"}},"outputs":[{"name":"stderr","text":"usage: colab_kernel_launcher.py [-h] --data DATA --ckpt CKPT\n                                [--block_size BLOCK_SIZE]\n                                [--batch_size BATCH_SIZE] [--iters ITERS]\n                                [--cpu]\ncolab_kernel_launcher.py: error: the following arguments are required: --data, --ckpt\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"],"ename":"SystemExit","evalue":"2","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"##from __future__ import annotations\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ---- Blocks (self-contained for isolation) ----\nclass CausalSelfAttention(nn.Module):\n    def __init__(self, n_embd: int, n_head: int, dropout: float = 0.0):\n        super().__init__()\n        assert n_embd % n_head == 0\n        self.n_head = n_head\n        self.d_head = n_embd // n_head\n        self.qkv = nn.Linear(n_embd, 3 * n_embd, bias=False)\n        self.proj = nn.Linear(n_embd, n_embd, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor):  # (B,T,C)\n        B, T, C = x.shape\n        qkv = self.qkv(x).view(B, T, 3, self.n_head, self.d_head)\n        q, k, v = qkv.unbind(dim=2)\n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        scale = 1.0 / math.sqrt(self.d_head)\n        # PyTorch SDPA (uses flash when available)\n        y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout.p if self.training else 0.0, is_causal=True)\n        y = y.transpose(1, 2).contiguous().view(B, T, C)\n        y = self.proj(y)\n        return y\n\nclass FeedForward(nn.Module):\n    def __init__(self, n_embd: int, mult: int = 4, dropout: float = 0.0):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, mult * n_embd),\n            nn.GELU(),\n            nn.Linear(mult * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    def __init__(self, n_embd: int, n_head: int, dropout: float):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.attn = CausalSelfAttention(n_embd, n_head, dropout)\n        self.ln2 = nn.LayerNorm(n_embd)\n        self.ffn = FeedForward(n_embd, mult=4, dropout=dropout)\n\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.ffn(self.ln2(x))\n        return x\n\n# ---- Tiny GPT ----\nclass GPT(nn.Module):\n    def __init__(self, vocab_size: int, block_size: int, n_layer: int = 4, n_head: int = 4, n_embd: int = 256, dropout: float = 0.0):\n        super().__init__()\n        self.block_size = block_size\n        self.tok_emb = nn.Embedding(vocab_size, n_embd)\n        self.pos_emb = nn.Embedding(block_size, n_embd)\n        self.drop = nn.Dropout(dropout)\n        self.blocks = nn.ModuleList([Block(n_embd, n_head, dropout) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd)\n        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n            if m.bias is not None:\n                nn.init.zeros_(m.bias)\n        elif isinstance(m, nn.Embedding):\n            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx: torch.Tensor, targets: torch.Tensor | None = None):\n        B, T = idx.shape\n        assert T <= self.block_size\n        pos = torch.arange(0, T, device=idx.device).unsqueeze(0)\n        x = self.tok_emb(idx) + self.pos_emb(pos)\n        x = self.drop(x)\n        for blk in self.blocks:\n            x = blk(x)\n        x = self.ln_f(x)\n        logits = self.head(x)\n        loss = None\n        if targets is not None:\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n        return logits, loss\n\n    @torch.no_grad()\n    def generate(self, idx: torch.Tensor, max_new_tokens: int = 200, temperature: float = 1.0,\n                top_k: int | None = 50, top_p: float | None = None):\n        from utils import top_k_top_p_filtering\n        self.eval()\n        # Guard: if the prompt is empty, start with a newline byte (10)\n        if idx.size(1) == 0:\n            idx = torch.full((idx.size(0), 1), 10, dtype=torch.long, device=idx.device)\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -self.block_size:]\n            logits, _ = self(idx_cond)\n            logits = logits[:, -1, :] / max(temperature, 1e-6)\n            logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n            probs = torch.softmax(logits, dim=-1)\n            next_id = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat([idx, next_id], dim=1)\n        return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:17:18.298728Z","iopub.execute_input":"2025-11-04T17:17:18.299424Z","iopub.status.idle":"2025-11-04T17:17:18.315785Z","shell.execute_reply.started":"2025-11-04T17:17:18.299401Z","shell.execute_reply":"2025-11-04T17:17:18.315154Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"\nimport argparse, time\nimport torch\n\n\n\ndef estimate_loss(model: GPT, ds: ByteDataset, args) -> dict:\n    model.eval()\n    out = {}\n    with torch.no_grad():\n        for split in ['train', 'val']:\n            losses = []\n            for _ in range(args.eval_iters):\n                xb, yb = ds.get_batch(split, args.batch_size, args.device)\n                _, loss = model(xb, yb)\n                losses.append(loss.item())\n            out[split] = sum(losses) / len(losses)\n    model.train()\n    return out\n\n\ndef train():\n    model.eval()\n    out = {}\n    with torch.no_grad():\n        for split in ['train', 'val']:\n            losses = []\n            for _ in range(args.eval_iters):\n                xb, yb = ds.get_batch(split, args.batch_size, args.device)\n                _, loss = model(xb, yb)\n                losses.append(loss.item())\n            out[split] = sum(losses) / len(losses)\n    model.train()\n    return out\n    p = argparse.ArgumentParser()\n    p.add_argument('--data', type=str, required=True)\n    p.add_argument('--out_dir', type=str, default='runs/min-gpt')\n    p.add_argument('--block_size', type=int, default=256)\n    p.add_argument('--batch_size', type=int, default=32)\n    p.add_argument('--n_layer', type=int, default=4)\n    p.add_argument('--n_head', type=int, default=4)\n    p.add_argument('--n_embd', type=int, default=256)\n    p.add_argument('--dropout', type=float, default=0.0)\n    p.add_argument('--steps', type=int, default=2000)\n    p.add_argument('--lr', type=float, default=3e-4)\n    p.add_argument('--weight_decay', type=float, default=0.1)\n    p.add_argument('--grad_clip', type=float, default=1.0)\n    p.add_argument('--eval_interval', type=int, default=200)\n    p.add_argument('--eval_iters', type=int, default=50)\n    p.add_argument('--sample_every', type=int, default=200)\n    p.add_argument('--sample_tokens', type=int, default=256)\n    p.add_argument('--temperature', type=float, default=1.0)\n    p.add_argument('--top_k', type=int, default=50)\n    p.add_argument('--top_p', type=float, default=None)\n    p.add_argument('--cpu', action='store_true')\n    p.add_argument('--compile', action='store_true')\n    p.add_argument('--amp', action='store_true')\n    args = p.parse_args()\n\n    args.device = torch.device('cuda' if torch.cuda.is_available() and not args.cpu else 'cpu')\n\n    tok = ByteTokenizer()\n    ds = ByteDataset(args.data, block_size=args.block_size)\n    model = GPT(tok.vocab_size, args.block_size, args.n_layer, args.n_head, args.n_embd, args.dropout).to(args.device)\n\n    if args.compile and hasattr(torch, 'compile'):\n        model = torch.compile(model)\n\n    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.95), weight_decay=args.weight_decay)\n    scaler = torch.cuda.amp.GradScaler(enabled=(args.amp and args.device.type == 'cuda'))\n\n    best_val = float('inf')\n    t0 = time.time()\n    model.train()\n    for step in range(1, args.steps + 1):\n        xb, yb = ds.get_batch('train', args.batch_size, args.device)\n        with torch.cuda.amp.autocast(enabled=(args.amp and args.device.type == 'cuda')):\n            _, loss = model(xb, yb)\n        opt.zero_grad(set_to_none=True)\n        scaler.scale(loss).backward()\n        if args.grad_clip > 0:\n            scaler.unscale_(opt)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n        scaler.step(opt)\n        scaler.update()\n\n        if step % 50 == 0:\n            print(f\"step {step:5d} | loss {loss.item():.4f} | {(time.time()-t0):.1f}s\")\n            t0 = time.time()\n\n        if step % args.eval_interval == 0:\n            losses = estimate_loss(model, ds, args)\n            print(f\"eval | train {losses['train']:.4f} | val {losses['val']:.4f}\")\n            if losses['val'] < best_val:\n                best_val = losses['val']\n                ckpt_path = f\"{args.out_dir}/model_best.pt\"\n                import os; os.makedirs(args.out_dir, exist_ok=True)\n                torch.save({'model': model.state_dict(), 'config': {\n                    'vocab_size': tok.vocab_size,\n                    'block_size': args.block_size,\n                    'n_layer': args.n_layer,\n                    'n_head': args.n_head,\n                    'n_embd': args.n_embd,\n                    'dropout': args.dropout,\n                }}, ckpt_path)\n                print(f\"saved checkpoint: {ckpt_path}\")\n\n        if args.sample_every > 0 and step % args.sample_every == 0:\n            start = torch.randint(low=0, high=len(ds.train) - args.block_size - 1, size=(1,)).item()\n            seed = ds.train[start:start + args.block_size].unsqueeze(0).to(args.device)\n            out = model.generate(seed, max_new_tokens=args.sample_tokens, temperature=args.temperature, top_k=args.top_k, top_p=args.top_p)\n            txt = tok.decode(out[0].cpu())\n            print(\"\\n================ SAMPLE ================\\n\" + txt[-(args.block_size + args.sample_tokens):] + \"\\n=======================================\\n\")\n\n    # final save\n    import os; os.makedirs(args.out_dir, exist_ok=True)\n    torch.save({'model': model.state_dict()}, f\"{args.out_dir}/model_final.pt\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:47:17.941659Z","iopub.execute_input":"2025-11-04T17:47:17.941912Z","iopub.status.idle":"2025-11-04T17:47:17.958516Z","shell.execute_reply.started":"2025-11-04T17:47:17.941895Z","shell.execute_reply":"2025-11-04T17:47:17.957795Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"\n\nimport argparse, torch\n\n\n\ndef sample():\n    p = argparse.ArgumentParser()\n    p.add_argument('--ckpt', type=str, required=True)\n    p.add_argument('--prompt', type=str, default='')\n    p.add_argument('--tokens', type=int, default=200)\n    p.add_argument('--temperature', type=float, default=1.0)\n    p.add_argument('--top_k', type=int, default=50)\n    p.add_argument('--top_p', type=float, default=None)\n    p.add_argument('--cpu', action='store_true')\n    args = p.parse_args()\n\n    device = torch.device('cuda' if torch.cuda.is_available() and not args.cpu else 'cpu')\n\n    tok = ByteTokenizer()\n    prompt_ids = tok.encode(args.prompt).unsqueeze(0).to(device)\n    if prompt_ids.numel() == 0:\n        # If no prompt provided, seed with newline byte (10)\n        prompt_ids = torch.tensor([[10]], dtype=torch.long, device=device)\n\n\n    ckpt = torch.load(args.ckpt, map_location=device)\n    config = ckpt.get('config', None)\n\n    if config is None:\n        # fall back to defaults\n        model = GPT(tok.vocab_size, block_size=256).to(device)\n        model.load_state_dict(ckpt['model'])\n    else:\n        model = GPT(**config).to(device)\n        model.load_state_dict(ckpt['model'])\n\n    with torch.no_grad():\n        out = model.generate(prompt_ids, max_new_tokens=args.tokens, temperature=args.temperature, top_k=args.top_k, top_p=args.top_p)\n    print(tok.decode(out[0].cpu()))\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom __future__ import annotations\nimport argparse, torch\nfrom dataset import ByteDataset\nfrom model_gpt import GPT\n\n\ndef eval_loss():\n    p = argparse.ArgumentParser()\n    p.add_argument('--data', type=str, required=True)\n    p.add_argument('--ckpt', type=str, required=True)\n    p.add_argument('--block_size', type=int, default=256)\n    p.add_argument('--batch_size', type=int, default=32)\n    p.add_argument('--iters', type=int, default=100)\n    p.add_argument('--cpu', action='store_true')\n    args = p.parse_args()\n\n    device = torch.device('cuda' if torch.cuda.is_available() and not args.cpu else 'cpu')\n\n    ds = ByteDataset(args.data, block_size=args.block_size)\n    ckpt = torch.load(args.ckpt, map_location=device)\n    cfg = ckpt.get('config', {\n        'vocab_size': 256,\n        'block_size': args.block_size,\n        'n_layer': 4,\n        'n_head': 4,\n        'n_embd': 256,\n        'dropout': 0.0,\n    })\n    model = GPT(**cfg).to(device)\n    model.load_state_dict(ckpt['model'])\n\n    model.eval()\n    losses = []\n    with torch.no_grad():\n        for _ in range(args.iters):\n            xb, yb = ds.get_batch('val', args.batch_size, device)\n            _, loss = model(xb, yb)\n            losses.append(loss.item())\n    print(f\"val loss: {sum(losses)/len(losses):.4f}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess, sys, pathlib, shlex\n\nROOT = pathlib.Path('/kaggle/input/llm-data/tiny.txt').resolve().parent\nRUNS = ROOT / 'runs' / 'min-gpt'\n\ndef run(cmd: str):\n    print(f\"\\n>>> {cmd}\")\n    res = subprocess.run(shlex.split(cmd), cwd=ROOT)\n    if res.returncode != 0:\n        sys.exit(res.returncode)\n\nif __name__ == '__main__':\n    # quick smoke training on a tiny file path tiny_hi.txt; adjust as needed\n    run(\"python train.py --data tiny_hi.txt --steps 400 --sample_every 100 --eval_interval 100 --batch_size 32 --block_size 128 --n_layer 2 --n_head 2 --n_embd 128\")\n\n    # sample from the best checkpoint\n    run(f\"python sample.py --ckpt {RUNS}/model_best.pt --tokens 200 --prompt 'Once upon a time '\")\n\n    # evaluate final val loss\n    run(f\"python eval_loss.py --data tiny_hi.txt --ckpt {RUNS}/model_best.pt --iters 50 --block_size 128\")\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:19:23.720184Z","iopub.execute_input":"2025-11-04T17:19:23.720949Z","iopub.status.idle":"2025-11-04T17:19:23.861699Z","shell.execute_reply.started":"2025-11-04T17:19:23.720922Z","shell.execute_reply":"2025-11-04T17:19:23.860810Z"}},"outputs":[{"name":"stdout","text":"\n>>> python train.py --data tiny_hi.txt --steps 400 --sample_every 100 --eval_interval 100 --batch_size 32 --block_size 128 --n_layer 2 --n_head 2 --n_embd 128\n","output_type":"stream"},{"name":"stderr","text":"python3: can't open file '/kaggle/input/llm-data/train.py': [Errno 2] No such file or directory\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"],"ename":"SystemExit","evalue":"2","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}],"execution_count":43}]}